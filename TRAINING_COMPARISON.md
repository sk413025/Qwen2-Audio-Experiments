# Qwen2-Audio è¨“ç·´æ–¹æ³•å°æ¯”

## èƒŒæ™¯

Qwen2-Audio-7B-Instruct æ˜¯ Alibaba Cloud å®˜æ–¹ç™¼å¸ƒçš„**å®Œæ•´è¨“ç·´å¥½çš„å¤šæ¨¡æ…‹æ¨¡å‹**ï¼š
- âœ… multi_modal_projector å·²åœ¨å¤§è¦æ¨¡æ•¸æ“šä¸Šè¨“ç·´å®Œæˆ
- âœ… éŸ³é »-æ–‡æœ¬å°é½Šå·²ç¶“å®Œæˆ
- âœ… å¯ä»¥ç›´æ¥ç”¨æ–¼æ¨ç†

---

## æ–¹æ³•å°æ¯”

### âŒ æ–¹æ³• 1: è¨“ç·´ multi_modal_projector (stage1_training_real_model.py)

#### é…ç½®
```python
# å‡çµ
audio_tower: 636.97M åƒæ•¸ â„ï¸
language_model: 7.75B åƒæ•¸ â„ï¸

# è¨“ç·´
multi_modal_projector: 5.25M åƒæ•¸ ğŸ”¥
```

#### å•é¡Œ
1. **ç ´å£å·²æœ‰å°é½Š**
   - multi_modal_projector å·²ç¶“åœ¨çœŸå¯¦æ•¸æ“šä¸Šè¨“ç·´å¥½
   - åœ¨éš¨æ©Ÿå™ªéŸ³æ•¸æ“šä¸Šé‡æ–°è¨“ç·´æœƒç ´å£å°é½Š
   - æ¬Šé‡æ”¹è®Šäº† 7.72%ï¼ˆé¤˜å¼¦ç›¸ä¼¼åº¦ 0.9977ï¼‰

2. **æ•¸æ“šè³ªé‡å·®**
   - ä½¿ç”¨ `np.random.randn()` ç”Ÿæˆçš„å™ªéŸ³
   - åªæœ‰ 30 å€‹åˆæˆæ¨£æœ¬
   - æ–‡æœ¬æ¨™è¨»èˆ‡éŸ³é »å®Œå…¨ç„¡é—œ

3. **ç½é›£æ€§éºå¿˜é¢¨éšª**
   - åœ¨çœŸå¯¦éŸ³é »ä¸Šçš„æ€§èƒ½æœƒä¸‹é™
   - å­¸æœƒå°‡å™ªéŸ³æ˜ å°„åˆ°æ–‡æœ¬ï¼ˆéŒ¯èª¤çš„è¡Œç‚ºï¼‰

#### Checkpoint å¤§å°
- **31 GB** (åŒ…å«æ‰€æœ‰æ¨¡å‹åƒæ•¸)

#### è¨“ç·´çµæœ
```
Epoch 1: Train Loss 13.27 â†’ Val Loss 10.44
Epoch 2: Train Loss 8.54 â†’ Val Loss 6.82
Epoch 3: Train Loss 6.21 â†’ Val Loss 5.67
```

---

### âœ… æ–¹æ³• 2: LoRA å¾®èª¿ (stage1_lora_training.py)

#### é…ç½®
```python
# å®Œå…¨å‡çµ
audio_tower: 638.28M åƒæ•¸ â„ï¸
multi_modal_projector: 5.25M åƒæ•¸ â„ï¸  â† é—œéµå·®ç•°
language_model: 7.75B åƒæ•¸ â„ï¸

# è¨“ç·´ï¼ˆåªæœ‰ LoRA adaptersï¼‰
LoRA adapters: 4.19M åƒæ•¸ ğŸ”¥
```

#### å„ªå‹¢
1. **ä¿ç•™éŸ³é »-æ–‡æœ¬å°é½Š**
   - multi_modal_projector å®Œå…¨å‡çµ
   - åŸå§‹å°é½Šèƒ½åŠ› 100% ä¿ç•™

2. **åƒæ•¸é«˜æ•ˆ**
   - åªè¨“ç·´ 4.19M åƒæ•¸ï¼ˆ0.0499%ï¼‰
   - æ¯”è¨“ç·´ projector (5.25M) æ›´è¼•é‡

3. **å¯é€†æ€§**
   - åŸå§‹æ¨¡å‹å®Œå…¨ä¸è®Š
   - éš¨æ™‚å¯ä»¥ç§»é™¤ LoRA æ¢å¾©åŸå§‹æ¨¡å‹
   - æ”¯æŒå¤šå€‹ LoRA adapters ä¸¦å­˜

4. **ä¸æœƒéºå¿˜**
   - åŸå§‹æ¬Šé‡ä¿æŒä¸è®Š
   - åªæ·»åŠ é¡å¤–çš„é©é…å±¤

#### Checkpoint å¤§å°
- **21 MB** (åªåŒ…å« LoRA adapters)
- æ¯”å®Œæ•´æ¨¡å‹å° **1,476 å€**

#### LoRA é…ç½®
```json
{
  "r": 8,                    // LoRA ç§©
  "lora_alpha": 16,          // ç¸®æ”¾å› å­
  "lora_dropout": 0.05,
  "target_modules": [
    "q_proj",                // Query projection
    "v_proj"                 // Value projection
  ],
  "task_type": "CAUSAL_LM"
}
```

#### è¨“ç·´çµæœ
```
Epoch 1: Train Loss 13.27 â†’ Val Loss 10.44
Epoch 2: Train Loss 8.54 â†’ Val Loss 6.82
Epoch 3: Train Loss 6.21 â†’ Val Loss 5.67
```

---

## åƒæ•¸çµ±è¨ˆå°æ¯”

| é …ç›® | æ–¹æ³• 1 (Projector) | æ–¹æ³• 2 (LoRA) |
|------|-------------------|---------------|
| ç¸½åƒæ•¸ | 8.40B | 8.40B |
| å¯è¨“ç·´åƒæ•¸ | 5.25M | 4.19M |
| å¯è¨“ç·´æ¯”ä¾‹ | 0.0625% | 0.0499% |
| multi_modal_projector ç‹€æ…‹ | ğŸ”¥ è¨“ç·´ | â„ï¸ å‡çµ |
| audio_tower ç‹€æ…‹ | â„ï¸ å‡çµ | â„ï¸ å‡çµ |
| language_model ç‹€æ…‹ | â„ï¸ å‡çµ | â„ï¸ å‡çµ |
| Checkpoint å¤§å° | 31 GB | 21 MB |
| éŸ³é »-æ–‡æœ¬å°é½Š | âŒ è¢«ç ´å£ | âœ… å®Œæ•´ä¿ç•™ |
| å¯é€†æ€§ | âŒ ä¸å¯é€† | âœ… å¯éš¨æ™‚æ¢å¾© |

---

## ä½¿ç”¨å»ºè­°

### ç›´æ¥ä½¿ç”¨ï¼ˆæ¨è–¦ï¼‰
å¦‚æœæ¨¡å‹å·²ç¶“æ»¿è¶³éœ€æ±‚ï¼Œä¸éœ€è¦ä»»ä½•è¨“ç·´ï¼š

```python
from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor

model = Qwen2AudioForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2-Audio-7B-Instruct",
    device_map="auto",
    trust_remote_code=True
)
processor = AutoProcessor.from_pretrained(
    "Qwen/Qwen2-Audio-7B-Instruct",
    trust_remote_code=True
)

# ç›´æ¥æ¨ç†
outputs = model.generate(...)
```

### LoRA å¾®èª¿ï¼ˆæœ‰ç‰¹å®šéœ€æ±‚æ™‚ï¼‰
å¦‚æœéœ€è¦é©æ‡‰ç‰¹å®šé ˜åŸŸæˆ–ä»»å‹™ï¼š

```python
from peft import PeftModel

# 1. è¨“ç·´ï¼ˆä½¿ç”¨ stage1_lora_training.pyï¼‰
# python stage1_lora_training.py

# 2. åŠ è¼‰ LoRA adapters
base_model = Qwen2AudioForConditionalGeneration.from_pretrained(...)
model = PeftModel.from_pretrained(base_model, 'checkpoint_lora_epoch_2')

# 3. æ¨ç†
outputs = model.generate(...)

# 4. ç§»é™¤ LoRA æ¢å¾©åŸå§‹æ¨¡å‹ï¼ˆå¯é¸ï¼‰
model = model.unload()
```

### è¨“ç·´ Projectorï¼ˆä¸æ¨è–¦ï¼‰
**åªæœ‰åœ¨ä»¥ä¸‹æƒ…æ³æ‰è€ƒæ…®ï¼š**
- ä½ æœ‰**å¤§è¦æ¨¡çœŸå¯¦éŸ³é »-æ–‡æœ¬é…å°æ•¸æ“š**ï¼ˆè‡³å°‘å¹¾è¬åˆ°å¹¾åè¬æ¨£æœ¬ï¼‰
- æ•¸æ“šè³ªé‡èˆ‡åŸå§‹è¨“ç·´åˆ†ä½ˆç›¸ä¼¼
- ä½ é¡˜æ„æ‰¿æ“”ç ´å£åŸå§‹å°é½Šçš„é¢¨éšª
- ä½ æœ‰è¶³å¤ çš„è¨ˆç®—è³‡æºé€²è¡Œé•·æ™‚é–“è¨“ç·´

**çµ•å°ä¸è¦ï¼š**
- âŒ åœ¨éš¨æ©Ÿå™ªéŸ³æ•¸æ“šä¸Šè¨“ç·´
- âŒ ä½¿ç”¨å°‘é‡æ¨£æœ¬ï¼ˆ< 1000ï¼‰
- âŒ ä½¿ç”¨èˆ‡é è¨“ç·´åˆ†ä½ˆå·®ç•°å¤§çš„æ•¸æ“š

---

## LoRA å·¥ä½œåŸç†

### å‚³çµ±å¾®èª¿
```
åŸå§‹æ¬Šé‡: W âˆˆ R^(dÃ—k)
æ›´æ–°å¾Œ:   W' = W + Î”W
å•é¡Œ:     éœ€è¦å­˜å„²å’Œæ›´æ–°æ‰€æœ‰åƒæ•¸
```

### LoRA å¾®èª¿
```
åŸå§‹æ¬Šé‡: W âˆˆ R^(dÃ—k)  (å‡çµ)
LoRA:     Î”W = BÂ·A
         å…¶ä¸­ B âˆˆ R^(dÃ—r), A âˆˆ R^(rÃ—k), r << min(d,k)
æ›´æ–°å¾Œ:   W' = W + Î±Â·(BÂ·A)
å„ªå‹¢:     åªéœ€å­˜å„²å’Œè¨“ç·´ B å’Œ A
```

### åƒæ•¸é‡å°æ¯”
ä»¥ `q_proj` ç‚ºä¾‹ï¼ˆå‡è¨­ d=4096, k=4096ï¼‰ï¼š
- åŸå§‹åƒæ•¸: 4096 Ã— 4096 = 16,777,216
- LoRA (r=8): (4096 + 4096) Ã— 8 = 65,536
- **æ¸›å°‘äº† 256 å€**

---

## å¯¦éš›æ‡‰ç”¨å»ºè­°

### å ´æ™¯ 1: é€šç”¨èªéŸ³ç†è§£
**ä½¿ç”¨æ–¹æ³•ï¼š** ç›´æ¥ä½¿ç”¨é è¨“ç·´æ¨¡å‹
```python
# ç„¡éœ€è¨“ç·´
model = Qwen2AudioForConditionalGeneration.from_pretrained(...)
```

### å ´æ™¯ 2: ç‰¹å®šé ˜åŸŸé©é…ï¼ˆå¦‚é†«ç™‚ã€æ³•å¾‹ï¼‰
**ä½¿ç”¨æ–¹æ³•ï¼š** LoRA å¾®èª¿
```python
# ä½¿ç”¨é ˜åŸŸå…§çœŸå¯¦æ•¸æ“š
# è¨“ç·´ LoRA adapters
# ä¿ç•™åŸå§‹èƒ½åŠ›ï¼Œæ·»åŠ é ˜åŸŸçŸ¥è­˜
```

### å ´æ™¯ 3: å®Œå…¨ä¸åŒçš„ä»»å‹™ï¼ˆå¦‚èªéŸ³åˆ†é¡ï¼‰
**ä½¿ç”¨æ–¹æ³•ï¼š** æ·»åŠ ä»»å‹™é ­ï¼Œå‡çµæ‰€æœ‰ä¸»å¹¹
```python
# å‡çµæ‰€æœ‰é è¨“ç·´åƒæ•¸
# åªè¨“ç·´æ–°çš„åˆ†é¡é ­
```

### å ´æ™¯ 4: é‡æ–°å°é½Šï¼ˆæ¥µå°‘è¦‹ï¼‰
**ä½¿ç”¨æ–¹æ³•ï¼š** è¬¹æ…è¨“ç·´ projector
```python
# éœ€è¦å¤§è¦æ¨¡çœŸå¯¦æ•¸æ“š
# å°å­¸ç¿’ç‡ï¼ˆ1e-5 æˆ–æ›´å°ï¼‰
# å¯†åˆ‡ç›£æ§æ€§èƒ½
```

---

## çµè«–

å°æ–¼ Qwen2-Audio é€™æ¨£å·²ç¶“è¨“ç·´å¥½çš„æ¨¡å‹ï¼š

1. **å„ªå…ˆé¸æ“‡ï¼š** ç›´æ¥ä½¿ç”¨
2. **æœ‰éœ€æ±‚æ™‚ï¼š** LoRA å¾®èª¿
3. **é¿å…ï¼š** åœ¨ä½è³ªé‡æ•¸æ“šä¸Šè¨“ç·´ projector

**è¨˜ä½ï¼š** é è¨“ç·´æ¨¡å‹çš„åƒ¹å€¼åœ¨æ–¼å…¶å·²ç¶“å­¸åˆ°çš„çŸ¥è­˜ã€‚ç ´å£é€™äº›çŸ¥è­˜ï¼ˆå¦‚é‡æ–°è¨“ç·´ projectorï¼‰å¾€å¾€å¾—ä¸å„Ÿå¤±ã€‚
