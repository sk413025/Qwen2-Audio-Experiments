# åŸºæ–¼ Transformer çš„ Domain Adapter ä½¿ç”¨æŒ‡å—

## è¨­è¨ˆç†å¿µ

### éˆæ„Ÿä¾†æºï¼šsequence_insertion_explained.py

å¾åºåˆ—æ’å…¥æ©Ÿåˆ¶ä¸­ç²å¾—çš„æ ¸å¿ƒæ´å¯Ÿï¼š

```
åºåˆ—æ’å…¥çš„ç²¾é«“ï¼š
- åœ¨**åºåˆ—ç¶­åº¦**æ“ä½œï¼ˆæ”¹è®Šåºåˆ—é•·åº¦ï¼‰
- ä¿æŒ**ç‰¹å¾µç¶­åº¦**ä¸è®Šï¼ˆ4096ç¶­ä¸è®Šï¼‰
- ä½¿ç”¨ Transformer Self-Attention è™•ç†èåˆ

Domain Adapter çš„é¡æ¯”ï¼š
- åŒæ¨£åœ¨**åºåˆ—ç¶­åº¦**æ“ä½œï¼ˆè™•ç†æ™‚åºé—œä¿‚ï¼‰
- ä¿æŒ**ç‰¹å¾µç¶­åº¦**ä¸è®Šï¼ˆ1280ç¶­ä¸è®Šï¼‰
- ä½¿ç”¨ Transformer Self-Attention å­¸ç¿’è½‰æ›
```

### æ ¸å¿ƒæ¦‚å¿µåœ–è§£

```
åºåˆ—æ’å…¥ï¼ˆSequence Insertionï¼‰:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [æ–‡å­—Token] + [éŸ³é »Embeddings] â†’ [èåˆåºåˆ—]    â”‚
â”‚                                                â”‚
â”‚ ç¶­åº¦è®ŠåŒ–ï¼š                                      â”‚
â”‚   [1, 11, 4096] + [1, 187, 4096]              â”‚
â”‚         â†“                                      â”‚
â”‚   [1, 197, 4096]  â† åºåˆ—é•·åº¦è®Šäº†ï¼Œç¶­åº¦ä¸è®Š      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Domain Adapterï¼ˆFeature Transformationï¼‰:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [LDVç‰¹å¾µ] â†’ [Transformer Adapter] â†’ [éº¥å…‹é¢¨é¢¨æ ¼] â”‚
â”‚                                                â”‚
â”‚ ç¶­åº¦è®ŠåŒ–ï¼š                                      â”‚
â”‚   [1, seq_len, 1280] â†’ [1, seq_len, 1280]    â”‚
â”‚         â†“                                      â”‚
â”‚   ç‰¹å¾µåˆ†ä½ˆèª¿æ•´ï¼Œç¶­åº¦ä¿æŒä¸è®Š â† åœ¨æ™‚åºç¶­åº¦å­¸ç¿’    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ¶æ§‹è¨­è¨ˆ

### å®Œæ•´æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Qwen2-Audio è™•ç†æµç¨‹                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LDV éŸ³é »æ³¢å½¢
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature Extractor  â”‚  [1, 128, 3000]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    audio_tower      â”‚  [1, 187, 1280]
â”‚   (Whisper-based)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Domain Adapter     â•‘  [1, 187, 1280]  â† æ–°æ’å…¥çš„æ¨¡çµ„
â•‘  (Transformer)      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ multi_modal_proj    â”‚  [1, 187, 4096]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sequence Insertion â”‚  [1, 197, 4096]
â”‚  (æ›¿æ› <|AUDIO|>)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    LLM (Qwen2)      â”‚  ç”Ÿæˆæ–‡æœ¬
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Domain Adapter å…§éƒ¨çµæ§‹

```python
class TransformerDomainAdapter(nn.Module):
    """
    è¼¸å…¥:  [batch, seq_len, 1280]  â† LDV ç‰¹å¾µ

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  + Position Encoding           â”‚  æ·»åŠ ä½ç½®ä¿¡æ¯
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Transformer Layer 1           â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ Multi-Head Self-Attn    â”‚   â”‚  æ•æ‰æ™‚åºé—œä¿‚
    â”‚  â”‚ - 8 heads               â”‚   â”‚
    â”‚  â”‚ - 1280 dim              â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚          â†“                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ Feed-Forward Network    â”‚   â”‚  ç‰¹å¾µè½‰æ›
    â”‚  â”‚ - 1280 â†’ 2048 â†’ 1280    â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Transformer Layer 2           â”‚  (åŒä¸Š)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Output Projection             â”‚
    â”‚  + LayerNorm                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Gate Mechanism (å¯é¸)         â”‚  å­¸ç¿’èª¿æ•´å¼·åº¦
    â”‚  sigmoid(Linear(x))            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Residual + Scale              â”‚
    â”‚  output = input + scale * Î”    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    è¼¸å‡º:  [batch, seq_len, 1280]  â† éº¥å…‹é¢¨é¢¨æ ¼ç‰¹å¾µ
    ```
```

---

## ç‚ºä»€éº¼ä½¿ç”¨ Transformerï¼Ÿ

### 1. **éŸ³é »æ˜¯æ™‚åºæ•¸æ“š**

éŸ³é »çš„ä¸åŒæ™‚é–“æ­¥ä¹‹é–“æœ‰å¼·çƒˆçš„ä¾è³´é—œä¿‚ï¼š

```
æ™‚é–“æ­¥:  tâ‚   tâ‚‚   tâ‚ƒ   tâ‚„   tâ‚…   ...  tâ‚â‚ˆâ‚‡
éŸ³é »:   [ç ´] [è£‚] [è²] [éŸ¿] [äº®]  ...  [éœ]
         â†‘    â†‘    â†‘    â†‘    â†‘
         â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜
              æ™‚åºé—œè¯
```

**Self-Attention çš„ä½œç”¨ï¼š**
- è®“æ¯å€‹æ™‚é–“æ­¥é—œæ³¨å…¶ä»–æ™‚é–“æ­¥
- æ•æ‰é•·è·é›¢ä¾è³´ï¼ˆå¦‚å›è²ã€æ··éŸ¿ï¼‰
- å­¸ç¿’æ™‚åºæ¨¡å¼

### 2. **é¡ä¼¼åºåˆ—æ’å…¥å¾Œçš„ Attention**

åºåˆ—æ’å…¥å¾Œï¼ŒTransformer çš„ Attention è®“ï¼š
- éŸ³é » embeddings äº’ç›¸é—œè¯ï¼ˆæ™‚åºå»ºæ¨¡ï¼‰
- éŸ³é »å’Œæ–‡å­— tokens äº’ç›¸é—œè¯ï¼ˆè·¨æ¨¡æ…‹ç†è§£ï¼‰

Domain Adapter çš„ Attention è®“ï¼š
- LDV ç‰¹å¾µçš„ä¸åŒæ™‚é–“æ­¥äº’ç›¸é—œè¯
- å­¸ç¿’ã€Œå“ªäº›æ™‚é–“æ­¥éœ€è¦èª¿æ•´ï¼Œå“ªäº›ä¸éœ€è¦ã€

### 3. **éˆæ´»çš„è½‰æ›èƒ½åŠ›**

```python
# ä¾‹å­ï¼šç»ç’ƒç ´ç¢è²
æ™‚é–“æ­¥ 92 (ç ´ç¢ç¬é–“):
  - Attend to æ™‚é–“æ­¥ 90-94 (ç ´ç¢å‰å¾Œ)
  - å¼·çƒˆèª¿æ•´ç‰¹å¾µåˆ†ä½ˆ

æ™‚é–“æ­¥ 150 (éœéŸ³æ®µ):
  - Attend to è‡ªå·±
  - å¹¾ä¹ä¸èª¿æ•´ï¼ˆgate â†’ 0ï¼‰
```

---

## åƒæ•¸é…ç½®æŒ‡å—

### é…ç½®é¸é …å°æ¯”

| é…ç½® | åƒæ•¸é‡ | é©ç”¨å ´æ™¯ | è¨ˆç®—é‡ |
|------|--------|---------|--------|
| **Lightweight** | ~8M | æ•¸æ“š < 5K | ä½ |
| - 1å±¤ Transformer<br>- 4 heads<br>- FFN 1024 | | å·®ç•°è¼ƒå° | |
| **Standard** | ~30M | æ•¸æ“š 5-20K | ä¸­ |
| - 2å±¤ Transformer<br>- 8 heads<br>- FFN 2048 | | ä¸­ç­‰å·®ç•° | |
| **Heavy** | ~60M | æ•¸æ“š > 20K | é«˜ |
| - 4å±¤ Transformer<br>- 16 heads<br>- FFN 4096 | | å·®ç•°å¾ˆå¤§ | |

### æ¨è–¦é…ç½®

#### å ´æ™¯ 1: å¿«é€ŸåŸå‹ï¼ˆæ•¸æ“š < 5Kï¼‰

```python
model = add_domain_adapter_to_model(
    model,
    adapter_type="lightweight",
    input_dim=1280,
    num_heads=4,
    ff_dim=1024,
    dropout=0.1
)
```

#### å ´æ™¯ 2: æ¨™æº–é…ç½®ï¼ˆæ•¸æ“š 5-20Kï¼‰

```python
model = add_domain_adapter_to_model(
    model,
    adapter_type="transformer",
    input_dim=1280,
    num_layers=2,
    num_heads=8,
    ff_dim=2048,
    dropout=0.1
)
```

#### å ´æ™¯ 3: é‡åº¦é©æ‡‰ï¼ˆæ•¸æ“š > 20Kï¼Œå·®ç•°æ¥µå¤§ï¼‰

```python
model = add_domain_adapter_to_model(
    model,
    adapter_type="transformer",
    input_dim=1280,
    num_layers=4,
    num_heads=16,
    ff_dim=4096,
    dropout=0.15
)
```

---

## å®Œæ•´ä½¿ç”¨æµç¨‹

### æ­¥é©Ÿ 1: æº–å‚™æ•¸æ“š

```python
# 1. æ”¶é›† LDV éŸ³é »
ldv_audio_files = [
    "ldv_sample_001.wav",
    "ldv_sample_002.wav",
    ...
]

# 2. æº–å‚™æ¨™è¨»ï¼ˆè½‰éŒ„æˆ–å°è©±ï¼‰
annotations = [
    {
        "audio": "ldv_sample_001.wav",
        "transcription": "æ©Ÿå™¨é‹è½‰æ­£å¸¸"
    },
    ...
]

# 3. è½‰æ›ç‚ºè¨“ç·´æ ¼å¼ï¼ˆé‡ç”¨ stage1_lora_training.py çš„æ•¸æ“šé›†é¡ï¼‰
from stage1_lora_training import Qwen2AudioTrainingDataset

train_data = prepare_ldv_data(ldv_audio_files, annotations)
train_dataset = Qwen2AudioTrainingDataset(train_data, processor)
```

### æ­¥é©Ÿ 2: åŠ è¼‰æ¨¡å‹ä¸¦æ·»åŠ  Adapter

```python
import torch
from transformers import AutoProcessor, Qwen2AudioForConditionalGeneration
from domain_adapter_transformer import add_domain_adapter_to_model

# åŠ è¼‰åŸºç¤æ¨¡å‹
model = Qwen2AudioForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2-Audio-7B-Instruct",
    torch_dtype=torch.float32,
    device_map="mps",
    trust_remote_code=True
)

processor = AutoProcessor.from_pretrained(
    "Qwen/Qwen2-Audio-7B-Instruct",
    trust_remote_code=True
)

# æ·»åŠ  Domain Adapter
model = add_domain_adapter_to_model(
    model,
    adapter_type="transformer",
    input_dim=1280,
    num_layers=2,
    num_heads=8,
    ff_dim=2048,
    dropout=0.1
)
```

### æ­¥é©Ÿ 3: è¨“ç·´

```python
from domain_adapter_transformer import train_with_domain_adapter
from torch.utils.data import DataLoader

# æº–å‚™ DataLoaderï¼ˆé‡ç”¨ stage1_lora_training.py çš„ collate_fnï¼‰
train_loader = DataLoader(
    train_dataset,
    batch_size=2,
    shuffle=True,
    collate_fn=collate_fn
)

# è¨“ç·´
model = train_with_domain_adapter(
    model=model,
    processor=processor,
    train_loader=train_loader,
    val_loader=val_loader,
    num_epochs=3,
    learning_rate=1e-4,
    device='mps'
)
```

### æ­¥é©Ÿ 4: ä¿å­˜å’ŒåŠ è¼‰

```python
# ä¿å­˜ï¼ˆåªä¿å­˜ Domain Adapterï¼‰
torch.save(
    model.domain_adapter.state_dict(),
    'ldv_domain_adapter.pt'
)

# åŠ è¼‰
model.domain_adapter.load_state_dict(
    torch.load('ldv_domain_adapter.pt')
)
```

### æ­¥é©Ÿ 5: æ¨ç†

```python
# è™•ç† LDV éŸ³é »
ldv_audio, sr = librosa.load('new_ldv_sample.wav', sr=16000)

conversation = [
    {
        'role': 'user',
        'content': [
            {'type': 'audio', 'audio_url': 'new_ldv_sample.wav'},
            {'type': 'text', 'text': 'è«‹åˆ†æé€™æ®µéŸ³é »'}
        ]
    }
]

text = processor.apply_chat_template(conversation, tokenize=False)
inputs = processor(text=text, audio=ldv_audio, return_tensors="pt")
inputs = {k: v.to('mps') for k, v in inputs.items()}

# ç”Ÿæˆï¼ˆDomain Adapter æœƒè‡ªå‹•æ‡‰ç”¨ï¼‰
outputs = model.generate(**inputs, max_new_tokens=256)
response = processor.batch_decode(outputs, skip_special_tokens=True)[0]
print(response)
```

---

## èˆ‡å…¶ä»–æ–¹æ³•å°æ¯”

| æ–¹æ³• | ä¿®æ”¹ä½ç½® | åƒæ•¸é‡ | ä¿ç•™å°é½Š | æ™‚åºå»ºæ¨¡ | æ¨è–¦åº¦ |
|------|---------|--------|---------|---------|--------|
| **è¨“ç·´ Projector** | projector | 5.25M | âŒ | âŒ | â­â­ |
| **LoRA on Projector** | projector + LoRA | ~100K | âœ… | âŒ | â­â­â­â­ |
| **Simple MLP Adapter** | audioâ†’proj ä¹‹é–“ | ~600K | âœ… | âŒ | â­â­â­ |
| **Transformer Adapter** â­ | audioâ†’proj ä¹‹é–“ | ~30M | âœ… | âœ… | â­â­â­â­â­ |

### Transformer Adapter çš„å„ªå‹¢

1. âœ… **å®Œå…¨ä¿ç•™ projector å°é½Š**
   - projector æ¬Šé‡ä¸è®Š
   - éŸ³é »-æ–‡æœ¬æ˜ å°„ä¿ç•™

2. âœ… **æ™‚åºå»ºæ¨¡èƒ½åŠ›**
   - Self-Attention æ•æ‰æ™‚åºé—œä¿‚
   - ç†è§£éŸ³é »çš„å‹•æ…‹è®ŠåŒ–

3. âœ… **éˆæ´»çš„é©æ‡‰èƒ½åŠ›**
   - Gate æ©Ÿåˆ¶ï¼šå­¸ç¿’ã€Œä½•æ™‚èª¿æ•´ï¼Œä½•æ™‚ä¸èª¿æ•´ã€
   - Scale åƒæ•¸ï¼šæ§åˆ¶èª¿æ•´å¼·åº¦

4. âœ… **å¯è§£é‡‹æ€§**
   - å¯è¦–åŒ– attention weights
   - ç†è§£å“ªäº›æ™‚é–“æ­¥è¢«èª¿æ•´

5. âœ… **æ“´å±•æ€§**
   - å¯è¨“ç·´å¤šå€‹ adaptersï¼ˆä¸åŒç’°å¢ƒï¼‰
   - å¯å‹•æ…‹åˆ‡æ›

---

## èª¿è©¦å’Œå„ªåŒ–

### æª¢æŸ¥ Adapter æ˜¯å¦å·¥ä½œ

```python
# 1. æª¢æŸ¥åƒæ•¸æ˜¯å¦å¯è¨“ç·´
for name, param in model.named_parameters():
    if 'domain_adapter' in name and param.requires_grad:
        print(f"{name}: {param.shape}")

# 2. æª¢æŸ¥å‰å‘å‚³æ’­
test_features = torch.randn(1, 187, 1280).to('mps')
output = model.domain_adapter(test_features)
print(f"è¼¸å…¥å½¢ç‹€: {test_features.shape}")
print(f"è¼¸å‡ºå½¢ç‹€: {output.shape}")  # æ‡‰è©²ç›¸åŒ

# 3. æª¢æŸ¥æ¢¯åº¦æµ
model.train()
# ... forward + backward ...
for name, param in model.domain_adapter.named_parameters():
    if param.grad is not None:
        print(f"{name}: grad_norm = {param.grad.norm().item():.4f}")
```

### å¸¸è¦‹å•é¡Œ

#### Q1: è¨“ç·´ loss ä¸ä¸‹é™ï¼Ÿ

**å¯èƒ½åŸå› ï¼š**
- Scale åƒæ•¸å¤ªå°ï¼ˆåˆå§‹ 0.1ï¼‰
- å­¸ç¿’ç‡å¤ªå°
- Adapter å¤ªå°ï¼Œè¡¨é”èƒ½åŠ›ä¸è¶³

**è§£æ±ºï¼š**
```python
# å¢å¤§ scale åˆå§‹å€¼
model.domain_adapter.scale.data = torch.ones(1) * 0.5

# ä½¿ç”¨ä¸åŒå­¸ç¿’ç‡
optimizer = AdamW([
    {'params': model.domain_adapter.scale, 'lr': 1e-3},
    {'params': [p for n, p in model.domain_adapter.named_parameters()
                if 'scale' not in n], 'lr': 1e-4}
])
```

#### Q2: åœ¨éº¥å…‹é¢¨éŸ³é »ä¸Šæ€§èƒ½ä¸‹é™ï¼Ÿ

**å¯èƒ½åŸå› ï¼š**
- Scale å¤ªå¤§ï¼Œéåº¦èª¿æ•´
- Gate å¤±æ•ˆï¼Œæ‰€æœ‰æ™‚é–“æ­¥éƒ½è¢«èª¿æ•´

**è§£æ±ºï¼š**
```python
# é™ä½ scale
model.domain_adapter.scale.data = torch.ones(1) * 0.05

# æª¢æŸ¥ gate è¼¸å‡º
with torch.no_grad():
    gate_values = model.domain_adapter.gate(features)
    print(f"Gate å‡å€¼: {gate_values.mean():.4f}")
    # æ‡‰è©²åœ¨ 0.3-0.7 ä¹‹é–“
```

#### Q3: é¡¯å­˜ä¸è¶³ï¼Ÿ

**è§£æ±ºï¼š**
```python
# ä½¿ç”¨ Lightweight ç‰ˆæœ¬
model = add_domain_adapter_to_model(
    model,
    adapter_type="lightweight",  # åƒæ•¸æ›´å°‘
    input_dim=1280,
    num_heads=4,
    ff_dim=1024
)

# æˆ–æ¸›å°‘ batch size
train_loader = DataLoader(dataset, batch_size=1)
```

---

## å¯¦é©—å»ºè­°

### å¯¦é©— 1: åŸºç·šæ¸¬è©¦ï¼ˆ1-2 å¤©ï¼‰

1. ä¸æ·»åŠ  Adapterï¼Œæ¸¬è©¦åŸå§‹æ¨¡å‹åœ¨ LDV ä¸Šçš„æ€§èƒ½
2. è¨˜éŒ„éŒ¯èª¤é¡å‹ï¼ˆç„¡æ³•è­˜åˆ¥ï¼Ÿè­˜åˆ¥éŒ¯èª¤ï¼Ÿï¼‰
3. å»ºç«‹æ€§èƒ½åŸºç·š

### å¯¦é©— 2: Lightweight Adapterï¼ˆ3-5 å¤©ï¼‰

1. ä½¿ç”¨ Lightweight é…ç½®
2. åœ¨ 2K LDV æ¨£æœ¬ä¸Šè¨“ç·´
3. æ¸¬è©¦æ€§èƒ½æå‡

### å¯¦é©— 3: æ¨™æº– Transformer Adapterï¼ˆ1-2 é€±ï¼‰

1. ä½¿ç”¨æ¨™æº–é…ç½®ï¼ˆ2 å±¤ï¼Œ8 headsï¼‰
2. åœ¨ 5-10K LDV æ¨£æœ¬ä¸Šè¨“ç·´
3. å°æ¯” Lightweight ç‰ˆæœ¬

### å¯¦é©— 4: æ¶ˆèç ”ç©¶ï¼ˆå¯é¸ï¼‰

æ¸¬è©¦ä¸åŒçµ„ä»¶çš„ä½œç”¨ï¼š
- ç§»é™¤ Gate æ©Ÿåˆ¶
- ç§»é™¤ Position Encoding
- èª¿æ•´å±¤æ•¸ã€é ­æ•¸
- èª¿æ•´ Scale åˆå§‹å€¼

---

## ç¸½çµ

### æ ¸å¿ƒå„ªå‹¢

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transformer Domain Adapter çš„æ ¸å¿ƒå„ªå‹¢              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. å€Ÿé‘’åºåˆ—æ’å…¥ï¼šåœ¨åºåˆ—ç¶­åº¦æ“ä½œï¼Œä¿æŒç‰¹å¾µç¶­åº¦      â”‚
â”‚  2. æ™‚åºå»ºæ¨¡ï¼šSelf-Attention æ•æ‰éŸ³é »æ™‚åºé—œä¿‚       â”‚
â”‚  3. ä¿ç•™å°é½Šï¼šå®Œå…¨ä¸ä¿®æ”¹ projector æ¬Šé‡             â”‚
â”‚  4. éˆæ´»é©æ‡‰ï¼šGate + Scale æ©Ÿåˆ¶æ§åˆ¶èª¿æ•´å¼·åº¦         â”‚
â”‚  5. å¯æ“´å±•æ€§ï¼šå¯è¨“ç·´å¤šå€‹ adaptersï¼Œå‹•æ…‹åˆ‡æ›         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### èˆ‡åºåˆ—æ’å…¥çš„ç²¾å¦™å°æ‡‰

| æ¦‚å¿µ | åºåˆ—æ’å…¥ | Domain Adapter |
|------|---------|---------------|
| **æ“ä½œç¶­åº¦** | åºåˆ—é•·åº¦ (seq_len) | åºåˆ—é•·åº¦ (seq_len) |
| **ä¿æŒä¸è®Š** | ç‰¹å¾µç¶­åº¦ (4096) | ç‰¹å¾µç¶­åº¦ (1280) |
| **æ ¸å¿ƒæ©Ÿåˆ¶** | Self-Attention | Self-Attention |
| **ç›®çš„** | èåˆå¤šæ¨¡æ…‹ | é©æ‡‰é ˜åŸŸå·®ç•° |
| **é—œéµæ´å¯Ÿ** | ä¿æŒç¶­åº¦ï¼Œæ”¹è®Šåºåˆ— | ä¿æŒç¶­åº¦ï¼Œèª¿æ•´ç‰¹å¾µ |

### ä¸‹ä¸€æ­¥

1. æº–å‚™ 5,000+ LDV éŸ³é »æ¨£æœ¬
2. å¾ Lightweight é…ç½®é–‹å§‹å¿«é€Ÿé©—è­‰
3. æ ¹æ“šçµæœèª¿æ•´åˆ°æ¨™æº–é…ç½®
4. è©•ä¼°åœ¨å…©ç¨®éŸ³é »ä¸Šçš„æ€§èƒ½
5. å„ªåŒ–è¶…åƒæ•¸

ç¥ä½ çš„ LDV é©æ‡‰é …ç›®é †åˆ©ï¼ğŸ¯
